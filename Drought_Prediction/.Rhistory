installed.packages('xgboost')
install.packages('xgboost')
install.packages('magrittr')
y8 = lm(current_fallow ~ latitude + longitude)
y8 = lm(current_fallow ~ latitude + longitude)summary(Regression)
summary(y1)
#independent variable
forest = c(81400, 25500, 6300, 6500, 3500, 91700, 4100, 27800)
non_agri = c(98500, 39700,	10000,	55900,	18800,	33700,	15500,	32200)
barren = c(9900,	17600,	10000,	15500,	10300,	25000,	6200,	9500)
pasture = c(43500,	36300,	12100,	19400,	15900,	38100,	16900,	9000)
misc = c(700,	4900,	1000,	2700,	2700,	7800,	1600,	4000)
culturable = c(8500,	20900,	11800,	8200,	20700,	32500,	40800,	24500)
fallow = c(20800,	34600,	17300,	25300,	18500,	7700,	12400,	6700)
current_fallow = c(99600,	78300,	30100,	28100,	41500,	90200,	10700,	3100)
sown = c(644800,	810800,	367500,	611000,	583800,	706400,	640300,	514300)
cropped = c(781400,	923800,	458600,	731500,	683300,	821600,	829200,	803300)
more_than_once_sown = c(13600,	113000,	91100,	120500,	99500,	115200,	188900,	289000)
pop = c(3701282,	2585049,	1177345,	1959046,	2454196,	3361292,	1657576,	1836086)
#Dependent variable
latitude = c(22.365086, 22.702335, 22.615114, 22.78732, 21.85, 31.922680)
longitude = c(85.437557, 85.927899, 84.495999, 86.2279, 84.03, 74.694023)
#Regression equation
y1 = lm(forest ~ latitude + longitude)
y2 = lm(non_agri ~ latitude + longitude)
y3 = lm(barren ~ latitude + longitude)
y4 = lm(pasture ~ latitude + longitude)
y5 = lm(misc ~ latitude + longitude)
y6 = lm(culturable ~ latitude + longitude)
y7 = lm(fallow ~ latitude + longitude)
y8 = lm(current_fallow ~ latitude + longitude)
y9 = lm(sown ~ latitude + longitude)
y10 = lm(cropped ~ latitude + longitude)
y11 = lm(more_than_once_sown ~ latitude + longitude)
y12 = lm(pop ~ latitude + longitude)
summary(y1)
summary(y2)
summary(y3)
summary(y4)
summary(y5)
summary(y6)
summary(y7)
summary(y8)
summary(y9)
summary(y10)
summary(y11)
summary(y12)
plot(y1)
#datas = read.csv('', header = TRUE)
#independent variable
forest = c(81400, 25500, 6300, 6500, 3500, 91700, 4100, 27800)
non_agri = c(98500, 39700, 10000, 55900, 18800, 33700, 15500, 32200)
barren = c(9900, 17600, 10000, 15500, 10300, 25000, 6200, 9500)
pasture = c(43500, 36300, 12100, 19400, 15900, 38100, 16900, 9000)
misc = c(700,	4900,	1000,	2700,	2700,	7800, 1600, 4000)
culturable = c(8500, 20900, 11800, 8200, 20700, 32500, 40800, 24500)
fallow = c(20800, 34600, 17300, 25300, 18500, 7700, 12400, 6700)
current_fallow = c(99600, 78300, 30100, 28100, 41500, 90200, 10700, 3100)
sown = c(644800, 810800, 367500, 611000, 583800, 706400, 640300, 514300)
cropped = c(781400,	923800,	458600,	731500,	683300,	821600,	829200,	803300)
more_than_once_sown = c(13600, 113000, 91100, 120500, 99500, 115200, 188900, 289000)
pop = c(3701282, 2585049, 1177345, 1959046, 2454196, 3361292, 1657576, 1836086)
#Dependent variable
latitude = c(22.365086, 22.702335, 22.615114, 22.78732, 21.85, 31.922680)
longitude = c(85.437557, 85.927899, 84.495999, 86.2279, 84.03, 74.694023)
#Regression equation
y1 = lm(forest ~ latitude + longitude)
y2 = lm(non_agri ~ latitude + longitude)
y3 = lm(barren ~ latitude + longitude)
y4 = lm(pasture ~ latitude + longitude)
y5 = lm(misc ~ latitude + longitude)
y6 = lm(culturable ~ latitude + longitude)
y7 = lm(fallow ~ latitude + longitude)
y8 = lm(current_fallow ~ latitude + longitude)
y9 = lm(sown ~ latitude + longitude)
y10 = lm(cropped ~ latitude + longitude)
y11 = lm(more_than_once_sown ~ latitude + longitude)
y12 = lm(pop ~ latitude + longitude)
summary(y1)
summary(y2)
summary(y3)
summary(y4)
summary(y5)
summary(y6)
summary(y7)
summary(y8)
summary(y9)
summary(y10)
summary(y11)
summary(y12)
plot(y1)
#datas = read.csv('', header = TRUE)
#independent variable
forest = c(81400, 25500, 6300, 6500, 3500, 91700, 4100, 27800)
non_agri = c(98500, 39700, 10000, 55900, 18800, 33700, 15500, 32200)
barren = c(9900, 17600, 10000, 15500, 10300, 25000, 6200, 9500)
pasture = c(43500, 36300, 12100, 19400, 15900, 38100, 16900, 9000)
misc = c(700,	4900,	1000,	2700,	2700,	7800, 1600, 4000)
culturable = c(8500, 20900, 11800, 8200, 20700, 32500, 40800, 24500)
fallow = c(20800, 34600, 17300, 25300, 18500, 7700, 12400, 6700)
current_fallow = c(99600, 78300, 30100, 28100, 41500, 90200, 10700, 3100)
sown = c(644800, 810800, 367500, 611000, 583800, 706400, 640300, 514300)
cropped = c(781400,	923800,	458600,	731500,	683300,	821600,	829200,	803300)
more_than_once_sown = c(13600, 113000, 91100, 120500, 99500, 115200, 188900, 289000)
pop = c(3701282, 2585049, 1177345, 1959046, 2454196, 3361292, 1657576, 1836086)
#Dependent variable
#(19.88, 18.9891, 19.72, 19.83, 18.4, 19.15, 18.17, 19.27)
#(75.33, 75.7601, 77.15, 75.88, 76.58, 77.33, 76.05, 76.78)
latitude = c(19.88, 18.9891, 19.72, 19.83, 18.4, 19.15, 18.17, 19.27)
longitude = c(75.33, 75.7601, 77.15, 75.88, 76.58, 77.33, 76.05, 76.78)
#Regression equation
y1 = lm(forest ~ latitude + longitude)
y2 = lm(non_agri ~ latitude + longitude)
y3 = lm(barren ~ latitude + longitude)
y4 = lm(pasture ~ latitude + longitude)
y5 = lm(misc ~ latitude + longitude)
y6 = lm(culturable ~ latitude + longitude)
y7 = lm(fallow ~ latitude + longitude)
y8 = lm(current_fallow ~ latitude + longitude)
y9 = lm(sown ~ latitude + longitude)
y10 = lm(cropped ~ latitude + longitude)
y11 = lm(more_than_once_sown ~ latitude + longitude)
y12 = lm(pop ~ latitude + longitude)
summary(y1)
summary(y2)
summary(y3)
summary(y4)
summary(y5)
summary(y6)
summary(y7)
summary(y8)
summary(y9)
summary(y10)
summary(y11)
summary(y12)
plot(y1)
install.packages('GMDH')
View(y1)
library("GMDH")
data("cancer")
data("cancer")
data("cancer")
out = fcast(cancer[1:66], method = "GMDH", input = 15, layer = 1, f.number = 5,level = 95, tf = "all", weight = 0.70, lambda = c(0, 0.01, 0.02, 0.04, 0.08, 0.16,0.32, 0.64, 1.28, 2.56, 5.12, 10.24))
data
data("cancer")
cancer = data("cancer")
cancer
cancer[0]
install.packages('GMDH')
data()
data('women')
out = fcast(women[1:66], method = "GMDH", input = 15, layer = 1, f.number = 5,level = 95, tf = "all", weight = 0.70, lambda = c(0, 0.01, 0.02, 0.04, 0.08, 0.16,0.32, 0.64, 1.28, 2.56, 5.12, 10.24))
data('women')
data('women')
print(data)
datas -> data('women')
print(datas)
datas -> data("women")
print(datas)
datas -> data("women")
head("women")
data("women")
#print(datas)
out = fcast(women[1:66], method = "GMDH", input = 15, layer = 1, f.number = 5,level = 95, tf = "all", weight = 0.70, lambda = c(0, 0.01, 0.02, 0.04, 0.08, 0.16,0.32, 0.64, 1.28, 2.56, 5.12, 10.24))
data("PlantGrowth")
#print(datas)
out = fcast(PlantGrowth[1:66], method = "GMDH", input = 15, layer = 1, f.number = 5,level = 95, tf = "all", weight = 0.70, lambda = c(0, 0.01, 0.02, 0.04, 0.08, 0.16,0.32, 0.64, 1.28, 2.56, 5.12, 10.24))
data("PlantGrowth")
head(PlantGrowth)
data("PlantGrowth")
#head(PlantGrowth)
#print(datas)
out = fcast(PlantGrowth[1:66], method = "GMDH", input = 15, layer = 1, f.number = 5,level = 95, tf = "all", weight = 0.70, lambda = c(0, 0.01, 0.02, 0.04, 0.08, 0.16,0.32, 0.64, 1.28, 2.56, 5.12, 10.24))
data("PlantGrowth")
#head(PlantGrowth)
#print(datas)
out = forecast(PlantGrowth[1:66], method = "GMDH", input = 15, layer = 1, f.number = 5,level = 95, tf = "all", weight = 0.70, lambda = c(0, 0.01, 0.02, 0.04, 0.08, 0.16,0.32, 0.64, 1.28, 2.56, 5.12, 10.24))
install.packages("MARSS")
library(MARSS)
library("MARSS")
library("MARSS")
MARSS(data, model=list(), fit=TRUE)
library("MARSS")
data -> data("cars")
MARSS(data, model=list(), fit=TRUE)
library("MARSS")
data -> data("cars")
data_matrix -> as.matrix(data)
MARSS(data, model=list(), fit=TRUE)
library("MARSS")
datas -> data("cars")
data_matrix -> as.matrix(datas)
MARSS(data, model=list(), fit=TRUE)
library("MARSS")
data("cars")
MARSS(data.matrix(cars), model=list(), fit=TRUE)
library("MARSS")
data("cancer")
MARSS(data.matrix(cancer[1:60]), model=list(), fit=TRUE)
library("MARSS")
data("cars")
MARSS(data.matrix(cars[1:60]), model=list(), fit=TRUE)
library("MARSS")
data("cars")
MARSS(data.matrix(cars[1:20]), model=list(), fit=TRUE)
library("MARSS")
data("cars")
MARSS(data.matrix(cars)[1:20], model=list(), fit=TRUE)
library("MARSS")
data("cars")
MARSS(data.matrix(cars)[1:20], model=list(), fit=TRUE)
MARSSparamCIs(data.matrix(cars)[1:20])
library(dplyr)
library(tseries)
library(MASS)
data <- read.csv('SPI_Aurangabad.csv', header = T)
#attach(data)
# To create time-series object
#spiarima <- ts(data$SPI ,frequency=12, start=c(1990,1))
#ts <- ts(data$SPI, start=c(2010,1), end=c(2017,12), frequency=12)
#plot(spiarima)
#title("time series plot lndata")
#dim(as.matrix(spiarima))
# Plot and convert to ln format
#data$SPI[1:1393] + 1
#min(data$SPI)
lnSPI = log(data$SPI[1058:1357]+1-min(data$SPI))  #translate and then transform
#View(lnSPI)
lnSP=1.931
# ACF, PACF and Dickey-Fuller Test
acf(lnSPI, lag.max=20, na.action = na.pass)
pacf(lnSPI, lag.max=20, na.action = na.pass)
# To check whether the dataset is stationary or not
adf.test(as.numeric(na.omit(lnSPI)))
#PP.test(ts)
#kpss.test(ts)
# To create time-series object
spiarima <- ts(lnSPI,frequency=12, start=c(2000,1))
#ts <- ts(data$SPI, start=c(2010,1), end=c(2017,12), frequency=12)
plot(spiarima)
title("time series plot lndata")
dim(as.matrix(spiarima))
components <- decompose(spiarima)
components
plot(components)
#Developing SARIMA model and Analysis of Model
library(forecast)
fitlnspi = auto.arima(spiarima, trace = TRUE, test = "kpss", ic="bic")
fitlnspi
summary(fitlnspi)
confint(fitlnspi)
x=exp(lnSP)
# Forecasted Values From ARIMA
arima_model.forecast = forecast(fitlnspi, h=35)
arima_model.forecast
plot(arima_model.forecast)
# the data needs to be converted back into its original format by calculating the exponent of the log predictions.
#These predictions are then compared against the test data to identify
forecastedvaluesextracted=as.numeric(arima_model.forecast$mean)
forecastedvaluesextracted
finalforecastvalues=exp(forecastedvaluesextracted) - 1 + min(data$SPI)
finalforecastvalues
# the forecasted values have been calculated
#compare this against the test data to forecast the percentage error:
# Percentage Error
df<-data.frame(data$SPI[1118:1392],finalforecastvalues)
col_headings<-c("Actual SPI","Forecasted SPI")
names(df)<-col_headings
#attach(df)
percentage_error=((df$'Actual SPI'-df$'Forecasted SPI')/(df$'Actual SPI'))
percentage_error
mean(percentage_error)
percentage_error=data.frame(abs(percentage_error))
accuracy=data.frame(percentage_error[percentage_error$abs.percentage_error. < 0.1,])
frequency=as.data.frame(table(accuracy))
sum(frequency$Freq)/(275/x)
#Residuals Diagonostics
plot.ts(fitlnspi$residuals)
Box.test(fitlnspi$residuals, lag=5, type = "Ljung-Box")
Box.test(fitlnspi$residuals, lag=10, type = "Ljung-Box")
Box.test(fitlnspi$residuals, lag=15, type = "Ljung-Box")
#acf(arima_model$residuals, lag.max = 24, main="ACF of the model")
Box.test(fitlnspi$residuals, lag=20, type = "Ljung-Box")
#library(tseries)
#jarque.bera.test(arima_model$residuals)
x = array(as.numeric(finalforecastvalues), dim=60)
#x[60]
#print(typeof(x))
for(i in 1:60)
{
if (x[i]<0 && x[i]>-0.99)
print("Mild Drought")
else if(x[i]<-1 && x[i]>-1.49)
print("Moderate Drought")
else if(x[i]<-1.5 && x[i]>-1.99)
print("Severe Drought")
else if(x[i]<-2)
print("Extreme Drought")
else
print("No Drought")
}
plot(finalforecastvalues, xlab = "Years", ylab = "SPI")
library(TSPred)
plotarimapred(data.test, finalforecastvalues, xlim = c(2016,2020), range.percent=0.05)
library(openxlsx)
library(writexl)
data <- data.frame(matrix(finalforecastvalues,nrow=35,ncol=1))
write_xlsx(data, "F:/mydata.xlsx")
library(dplyr)
library(tseries)
library(MASS)
data <- read.csv('SPI_Aurangabad.csv', header = T)
#attach(data)
# To create time-series object
#spiarima <- ts(data$SPI ,frequency=12, start=c(1990,1))
#ts <- ts(data$SPI, start=c(2010,1), end=c(2017,12), frequency=12)
#plot(spiarima)
#title("time series plot lndata")
#dim(as.matrix(spiarima))
# Plot and convert to ln format
#data$SPI[1:1393] + 1
#min(data$SPI)
lnSPI = log(data$SPI[1058:1357]+1-min(data$SPI))  #translate and then transform
#View(lnSPI)
lnSP=1.931
# ACF, PACF and Dickey-Fuller Test
acf(lnSPI, lag.max=20, na.action = na.pass)
pacf(lnSPI, lag.max=20, na.action = na.pass)
# To check whether the dataset is stationary or not
adf.test(as.numeric(na.omit(lnSPI)))
#PP.test(ts)
#kpss.test(ts)
# To create time-series object
spiarima <- ts(lnSPI,frequency=12, start=c(2000,1))
#ts <- ts(data$SPI, start=c(2010,1), end=c(2017,12), frequency=12)
plot(spiarima)
title("time series plot lndata")
dim(as.matrix(spiarima))
components <- decompose(spiarima)
components
plot(components)
#Developing SARIMA model and Analysis of Model
library(forecast)
fitlnspi = auto.arima(spiarima, trace = TRUE, test = "kpss", ic="bic")
fitlnspi
summary(fitlnspi)
confint(fitlnspi)
x=exp(lnSP)
# Forecasted Values From ARIMA
arima_model.forecast = forecast(fitlnspi, h=35)
arima_model.forecast
plot(arima_model.forecast)
# the data needs to be converted back into its original format by calculating the exponent of the log predictions.
#These predictions are then compared against the test data to identify
forecastedvaluesextracted=as.numeric(arima_model.forecast$mean)
forecastedvaluesextracted
finalforecastvalues=exp(forecastedvaluesextracted) - 1 + min(data$SPI)
finalforecastvalues
# the forecasted values have been calculated
#compare this against the test data to forecast the percentage error:
# Percentage Error
df<-data.frame(data$SPI[1118:1392],finalforecastvalues)
col_headings<-c("Actual SPI","Forecasted SPI")
names(df)<-col_headings
#attach(df)
percentage_error=((df$'Actual SPI'-df$'Forecasted SPI')/(df$'Actual SPI'))
percentage_error
mean(percentage_error)
percentage_error=data.frame(abs(percentage_error))
accuracy=data.frame(percentage_error[percentage_error$abs.percentage_error. < 0.1,])
frequency=as.data.frame(table(accuracy))
sum(frequency$Freq)/(275/x)
#Residuals Diagonostics
plot.ts(fitlnspi$residuals)
Box.test(fitlnspi$residuals, lag=5, type = "Ljung-Box")
Box.test(fitlnspi$residuals, lag=10, type = "Ljung-Box")
Box.test(fitlnspi$residuals, lag=15, type = "Ljung-Box")
#acf(arima_model$residuals, lag.max = 24, main="ACF of the model")
Box.test(fitlnspi$residuals, lag=20, type = "Ljung-Box")
#library(tseries)
#jarque.bera.test(arima_model$residuals)
x = array(as.numeric(finalforecastvalues), dim=60)
#x[60]
#print(typeof(x))
for(i in 1:60)
{
if (x[i]<0 && x[i]>-0.99)
print("Mild Drought")
else if(x[i]<-1 && x[i]>-1.49)
print("Moderate Drought")
else if(x[i]<-1.5 && x[i]>-1.99)
print("Severe Drought")
else if(x[i]<-2)
print("Extreme Drought")
else
print("No Drought")
}
plot(finalforecastvalues, xlab = "Years", ylab = "SPI")
library(TSPred)
plotarimapred(data.test, finalforecastvalues, xlim = c(2016,2020), range.percent=0.05)
library(openxlsx)
library(writexl)
data <- data.frame(matrix(finalforecastvalues,nrow=35,ncol=1))
write_xlsx(data, "F:/mydata.xlsx")
install.packages('dplyr')
install.packages("dplyr")
library(dplyr)
library(tseries)
library(MASS)
library(dplyr)
library(tseries)
library(MASS)
data <- read.csv('SPI_Aurangabad.csv', header = T)
data <- read.csv('SPI_Aurangabad.csv', header = T)
# Plot and convert to ln format
#data$SPI[1:1393] + 1
#min(data$SPI)
lnSPI = log(data$SPI[1058:1357]+1-min(data$SPI))  #translate and then transform
setwd("C:/xampp/htdocs/beproject/Drought_Prediction")
install.packages("dplyr")
library(dplyr)
library(tseries)
library(MASS)
data <- read.csv('SPI_Aurangabad.csv', header = T)
# Plot and convert to ln format
#data$SPI[1:1393] + 1
#min(data$SPI)
lnSPI = log(data$SPI[1058:1357]+1-min(data$SPI))  #translate and then transform
#View(lnSPI)
lnSP=1.931
# ACF, PACF and Dickey-Fuller Test
acf(lnSPI, lag.max=20, na.action = na.pass)
